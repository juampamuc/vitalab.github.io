---
layout: review
title: "Equivariant Spherical Deconvolution: Learning Sparse Orientation
Distribution Functions from Spherical Data"
tags: brain deep-learning dMRI fODF medical spherical-CNN SH tractography U-Net white-matter
author: "Jon Haitz Legarreta Gorroño"
cite:
    authors: "Axel Elaldi and Neel Dey et al."
    title: "Equivariant Spherical Deconvolution: Learning Sparse Orientation
    Distribution Functions from Spherical Data"
    venue: "IPMI 2021"
pdf: "https://arxiv.org/pdf/2102.09462.pdf"
---


# Highlights

- Authors present a rotation-equivariant unsupervised learning framework for
fODF estimation on diffusion data.
- Their approach outperforms conventional fODF estimation methods and shows an
improved ability to resolve fODFs at small crossing angles.


# Introduction

Diffusion-weighted MRI (dMRI) enables to investigate *in vivo* the white matter
tissue microstructure and fiber configuration. Local reconstruction methods
allow to reconstruct such configuration under the form of fiber Orientation
Distribution Functions (fODFs).

Authors argue that:
- Supervised deep learning approaches that have been proposed for this task are
limited by the quality of the MSMT-CSD (Multi-Shell, Multi-Tissue Constrained
Spherical Deconvolution) fit used for training, and that are not equivariant to
spherical rotation in general.
- Regular (planar) convolutional networks are constructed for equivariance to
planar translation. The analogous for spherical signals being rotation,
spherical convolution is more appropriate for estimating fODFs from diffusion
data.

To overcome these issues, authors introduce an unsupervised fODF estimation
framework using rotation-equivariant spherical convolutional networks.

The relevant spherical and graph CNN literature can be found in [1], [2], [3], [4]

# Methods

Taking advantage of the fact the dMRI is a function defined on the sphere,
authors propose to discretize the sphere as a graph $$\mathcal{G}$$ such that
$$f : \mathcal{S}^{2} \rightarrow \mathbb{R}^{B}$ is sampled on the $$N$$
vertices of $$\mathcal{G}$$ such that the signal becomes a matrix
$$\mathbf{f} \in \mathcal{M}_{N,B} (\mathbb{R})$$, where $$\mathcal{M}_{N,B}$$
is the dMRI signal sampled on the sphere over the $$B$$ shells. The graph
convolution is written as $$h(\mathbf{L}) \mathbf{f} = \sum_{i=0}^{P} w_{i} \mathbf{L}^{}i \mathbf{f}$$,
where the $$\{w_{i}\}$$ are the convolutional filter weights, and
$$\mathbf{L} = \mathbf{D} - \mathbf{A}$$ is the graph Laplacian with degree
matrix $$\mathbf{D}$$ and adjacency matrix $$\mathbf{A}$$ (see reference [4] to
know about the degree and adjacency matrices, and in general, how to construct
the graph from the dMRI signal).

![](/article/images/ESD/Architecture.jpg)

Authors use a hierarchical Healpix sampling method [4] of the sphere to
construct their graph. They use SH interpolation to resample the diffusion
signal onto the Healpix grid.

They finally get their input signal as $$\mathbf{S}_{input} \in \mathcal{M}_{V,B,n} (\mathbb{R})$$,
where $$V$$ is the number of voxels in a batch, $$B$$ is the number of shells,
and $$N$$ is the number of vertices.

Their learning framework minimizes the following loss function:

![](/article/images/ESD/Loss.jpg)

where the first term is the signal reconstruction; the second one is the
regularization term, an $$L_{1}$$ norm that assumes that fODFs follow a
heavy-tailed Cauchy distribution and ensure their sparsity; and the third term
encourages non-negativity in the fODFs that might appear in the fODFs
estimated by the network.

The reconstructed signal includes the multi-tissue information.


## Data

- They generate a noisy synthetic multi-tissue diffusion models with a varying
number of gradients and a single shell value, as well as multi-shell data.
- To asses the effect on downstream tasks they track on the ISMRM 2015
Tractography Challenge data
- They use an additional *in vivo* human multi-shell dataset to evaluate the
performance on such data.

# Results

For the synthetic dataset, their baseline method is the CSD implementation
available in MRTrix3.

For the tractography assessment they use the Tractometer tool.

For the synthetic model:
- ESD shows a decreased angular error providing sharper fODFs and is able to
reduce the number of spurious fibers detected.
- ESD provides a better partial volume fraction estimation.

![](/article/images/ESD/Results_graphs.jpg)

For the ISMRM 2015 Tractogrpahy Challenge:
- ESD allows for a more accurate fiber tracking: increase the fraction of valid
connections (VC) while decreasing the fraction of invalid connections (IC) and
non-connected streamlines (NC).

For the human *in vivo* dataset
- ESD shows a decreased KL divergence in the estimated tissue volume fractions.
- Streamlines derived from ESD fODF estimations are less noisy.

![](/article/images/ESD/Results_fODF.jpg)

![](/article/images/ESD/Results_tractography_table.jpg)

![](/article/images/ESD/Results_tractography_tractograms.jpg)

Note: esd++csd (or ESD++CSD) means the concatenation of CSD deconvolutions to
the input of the network to investigate whether feature engineering provides
performance improvements.


# Conclusions

- Authors have proposed an unsupervised rotation-equivariant spherical CNN
framework for fODF estimation.
- Their results show an increased ability to resolve smaller-angle crossing
fibers, improve fiber localization, and better partial volume estimation over
state-of-the-art CSD-based methods.
- Its benefits in downstream pipeline tasks (tractography) are also highlighted.


# Comments

- Authors use SHs of degree 20. The number of gradient encoding directions
needed to represent that signal are 231 ($$R = (l_{max}+1)(l_{max}+2)/2$$),
which is a much larger value than any of the ones used in the experimental
setting. It is unclear if the SH interpolation used gets all those 231
coefficients.
- It is unclear why they denote that there are 8 coefficients (when they are
using 20) in Fig. 2.


# References
^[1] Cohen, T., Welling, M.: Group equivariant convolutional networks. In: Interna-
tional conference on machine learning. pp. 2990–2999 (2016)

[2] Cohen, T.S., Geiger, M., Köhler, J., Welling, M.: Spherical CNNs. In: International
Conference on Learning Representations (2018)

[3] Gorski, K.M., Wandelt, B.D., Hansen, F.K., Hivon, E., Banday, A.J.: The healpix
primer. arXiv preprint astro-ph/9905275 (1999)

[4] Perraudin, N., Defferrard, M., Kacprzak, T., Sgier, R.: Deepsphere: Efficient spher-
ical convolutional neural network with healpix sampling for cosmological applica-
tions. Astronomy and Computing 27, 130–146 (2019)


DeepSphere: a graph-based spherical CNN
Michaël Defferrard, Martino Milani, Frédérick Gusset, Nathanaël Perraudin
